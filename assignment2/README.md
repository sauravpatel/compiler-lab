This is a basic lexical analyzer. This takes as input a file containing regular expressions. This is then used to create a e-NFA, which is then modified to get a DFA and then a minimal DFA.
Using this DFA, we perform a lexical analysis and split the input file into tokens, and store this output file. Also the symbol table is generated.
